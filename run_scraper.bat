@echo off
REM Whop Scraper Full Pipeline Script (Windows)
REM This script runs the complete scraping pipeline:
REM 1. Sets up environment and dependencies
REM 2. Extracts URLs from sitemaps (explore.py)
REM 3. Scrapes community data (scrape_new.py)
REM 4. Ranks and analyzes data (rank.py)

echo ==========================================
echo WHOP SCRAPER FULL PIPELINE
echo ==========================================
echo Starting at: %date% %time%
echo.

REM Step 1: Activate virtual environment (if it exists)
if exist "venv\Scripts\activate.bat" (
    echo üîß Activating virtual environment...
    call venv\Scripts\activate.bat
    echo ‚úÖ Virtual environment activated
) else if exist ".venv\Scripts\activate.bat" (
    echo üîß Activating virtual environment...
    call .venv\Scripts\activate.bat
    echo ‚úÖ Virtual environment activated
) else (
    echo ‚ö†Ô∏è  No virtual environment found, using system Python
)

echo.

REM Step 2: Install/update requirements
echo üì¶ Installing Python requirements...
if exist "requirements.txt" (
    pip install -r requirements.txt
    echo ‚úÖ Requirements installed
) else (
    echo ‚ö†Ô∏è  No requirements.txt found, installing basic packages...
    pip install requests beautifulsoup4 lxml
)

echo.

REM Step 3: Create output directory
echo üìÅ Creating output directory...
if not exist "output" mkdir output
echo ‚úÖ Output directory ready

echo.

REM Step 4: Run explore.py to extract URLs from sitemaps
echo üîç Step 1/3: Running explore.py to extract community URLs...
echo This will fetch all XML sitemaps and extract product URLs...
python explore.py

if not exist "output\sample_discovery.txt" (
    echo ‚ùå Error: sample_discovery.txt not created by explore.py
    pause
    exit /b 1
)

for /f %%i in ('find /c /v "" ^< output\sample_discovery.txt') do set URL_COUNT=%%i
echo ‚úÖ Found %URL_COUNT% product sitemap URLs

echo.

REM Step 5: Run scrape_new.py to scrape community data
echo üï∑Ô∏è  Step 2/3: Running scrape_new.py to scrape community data...
echo This will extract community URLs from product sitemaps and scrape each page...
python scrape_new.py

if not exist "output\raw_communities.json" (
    echo ‚ùå Error: raw_communities.json not created by scrape_new.py
    pause
    exit /b 1
)

for /f %%i in ('python -c "import json; data=json.load(open('output/raw_communities.json')); print(len(data))"') do set COMMUNITY_COUNT=%%i
echo ‚úÖ Scraped %COMMUNITY_COUNT% communities

echo.

REM Step 6: Run rank.py to analyze and rank data
echo üìä Step 3/3: Running rank.py to rank and analyze communities...
python rank.py

if not exist "output\ranked_communities.csv" (
    echo ‚ùå Error: ranked_communities.csv not created by rank.py
    pause
    exit /b 1
)

echo ‚úÖ Rankings generated

echo.

REM Step 7: Summary
echo ==========================================
echo üéâ PIPELINE COMPLETED SUCCESSFULLY!
echo ==========================================
echo Completed at: %date% %time%
echo.
echo üìã RESULTS SUMMARY:
echo    ‚Ä¢ Product sitemaps processed: %URL_COUNT%
echo    ‚Ä¢ Communities scraped: %COMMUNITY_COUNT%
echo    ‚Ä¢ Output files created:
echo      - output\sample_discovery.txt (product sitemap URLs)
echo      - output\raw_communities.json (scraped community data)
echo      - output\ranked_communities.csv (top ranked communities)
echo      - output\all_communities_ranked.json (full ranked data)
echo.
echo üöÄ Ready for analysis! Check the output\ directory for results.
echo.

REM Optional: Show top 5 communities
echo üèÜ TOP 5 COMMUNITIES:
powershell -Command "Get-Content output\ranked_communities.csv | Select-Object -First 6"

echo.
echo Press any key to exit...
pause >nul